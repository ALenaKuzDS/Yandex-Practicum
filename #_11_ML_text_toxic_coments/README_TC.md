# Токсичные комментарии

## Данные:
В вашем распоряжении набор данных с разметкой о токсичности правок.
Столбец text в нём содержит текст комментария, а toxic — целевой признак.

## Задача
Построить модель, которая будет искать токсичные комментарии и отправлять их на модерацию. Значением F1 должно быть не менее 0.75.

## Ипользуемые библиотеки 
pandas, numpy, seaborn, matplotlib, sklearn, catboost, nltk

## Cтатуса проекта 
Закончен
